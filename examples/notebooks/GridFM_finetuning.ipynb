{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridFM Fine-Tuning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we exploit the previously pre-trained reconstruction model to demonstrate the concept of fine-tuning. We exploit the power-flow problem, as a low-entry barrier example on how to fine-tune more complex downstream tasks in the future.\n",
    "Thus, the overall workflow consists of:\n",
    "\n",
    "1. As with the pre-training, the first step is to normalize the fine-tuning data and convert the network and power flow solution into a pytorch geometric graph representation\n",
    "2. Data Loader then loads the data for fine-tuning\n",
    "3. In the PF use-case, which is most closely related to the pre-training, we simply need to adjust the masking strategy to correspond to the PF problem, i.e. no longer random masking. For other use-cases, it may even be necessary to replace the decoder or add an additional head or decoder layer to the pre-trained autoencoder.\n",
    "4. Then the model is trained to reconstruct the PF grid-state. As a loss, the standard \"means square/absolute\" error is used together with a physics informed loss, based on node-wise power balance equations (what comes in needs to get out...or be absorbed).\n",
    "5. Once fine-tuned, we visualize fine-tuning performance and PF grid-state reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "# IBM GridFM library\n",
    "from gridFM.datasets.powergrid import GridDatasetMem\n",
    "from gridFM.datasets.data_normalization import BaseMVANormalizer\n",
    "from gridFM.training.trainer import Trainer\n",
    "from gridFM.datasets.utils import split_dataset\n",
    "from gridFM.datasets.transforms import AddPFMask\n",
    "from gridFM.training.callbacks import EarlyStopper\n",
    "from gridFM.training.plugins import MetricsTrackerPlugin\n",
    "from gridFM.utils.loss import PBELoss\n",
    "\n",
    "# Standard Libraries\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Training Data and Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from which grid case file the simulated AC powerflow data should be used\n",
    "data_dir = \"../data/case30_ieee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_normalizer, edge_normalizer = (\n",
    "    BaseMVANormalizer(node_data=True),\n",
    "    BaseMVANormalizer(node_data=False),\n",
    ")\n",
    "\n",
    "dataset = GridDatasetMem(\n",
    "    root=data_dir,\n",
    "    norm_method=\"baseMVAnorm\",\n",
    "    node_normalizer=node_normalizer,\n",
    "    edge_normalizer=edge_normalizer,\n",
    "    pe_dim=20,  # Dimension of positional encoding\n",
    "    transform=AddPFMask(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_normalizer.to(device)\n",
    "edge_normalizer.to(device)\n",
    "\n",
    "train_dataset, val_dataset, _ = split_dataset(\n",
    "    dataset, data_dir, val_ratio=0.1, test_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pytorch Dataloaders for Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders with batches. The data-Loaders also take care of the masking for the powerflow problem formulation, the masking strategy in the configuration yaml needs to be set to \"pf\".\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\n",
    "    \"../models/GridFM_v0_2_3.pth\", weights_only=False, map_location=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select optimizer and learning rate scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    ")\n",
    "# Adjust learning rate while training\n",
    "scheduler = ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block only for compatibility with original code - does not do anything here\n",
    "best_model_path = os.path.join(\"best_checkpoint.pth\")\n",
    "early_stopper = EarlyStopper(best_model_path, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = PBELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plugin logs validation losses and saves to file for later use\n",
    "log_val_loss_plugin = MetricsTrackerPlugin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Trainer Instance -> /gridFM/training/trainer.py\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    early_stopper=early_stopper,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    lr_scheduler=scheduler,\n",
    "    plugins=[log_val_loss_plugin],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss vs. training epochs\n",
    "val_loss = log_val_loss_plugin.get_losses()\n",
    "plt.plot(val_loss)\n",
    "plt.grid()\n",
    "plt.title(\"PF Finetuning Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
