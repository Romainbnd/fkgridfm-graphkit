networks: ["GBreducednetwork_OPFLearn"]
seed: 42
verbose: False
data:
  input_dim: 9
  output_dim: 6
  edge_dim: 2
  # Normalization method to use. Available options:
  # - "minmax": Scales data between the minimum and maximum values.
  # - "standard": Standardizes data to have zero mean and unit variance.
  # - "baseMVAnorm": Divides data by a baseMVA value for normalization, need to specify the baseMVA parameter separately
  # - "identity": Does not apply any normalization, leaves data unchanged.
  normalization: "minmax"
  baseMVA: 100
  mask_dim: 6
  mask_ratio: 0.5
  mask_value: 0.0
  learn_mask: False
  scenarios: [99000]
training:
  batch_size: 32
  num_layers: 5
  hidden_size: 64
  attention_head: 8
  epochs: 100
  # Losses to use during training. Available losses:
  # - "MSE": Mean Squared Error
  # - "MaskedMSE": Masked Mean Squared Error
  # - "SCE": Scaled Cosing Error
  # - "PBE": Power Balance Equation loss
  losses: ["MaskedMSE"]
  loss_weights: [1.0]
optimizer:
  learning_rate: 0.0001
  beta1: 0.9
  beta2: 0.999
  lr_decay: 0.7
  lr_patience: 3
data_split:
  val_ratio: 0.1
  test_ratio: 0.1
callbacks:
  patience: -1 # -1 means no early stopping, 0 means stop training the first time the validation loss increases
  tol: 0 # tolerance for considering the validation loss as worse than best one so far